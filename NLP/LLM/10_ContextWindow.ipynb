{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfa1cbc4",
   "metadata": {},
   "source": [
    "### 10. Context Window Yapısı\n",
    "\n",
    "### Context Window Nedir?\n",
    "\n",
    "**Context Window**, bir büyük dil modelinin (LLM) bir seferde işleyebileceği maksimum token (kelime veya alt kelime) sayısıdır.\n",
    "\n",
    "- **Token**: \"merhaba\" = 1 token, \"çalışmıyorum\" = \"çalış\" + \"mıyorum\" = 2 token (WordPiece).\n",
    "- **Örnek**: GPT-4 Turbo: 128K token, Llama 3: 8K token, bazı modeller: 4K token.\n",
    "\n",
    "---\n",
    "\n",
    "### Neden Önemli?\n",
    "\n",
    "- **Uzun metinler** (raporlar, kitaplar) tamamıyle işlenemez.\n",
    "- Model, **bağlam kaybı** yaşayabilir (daha önce bahsedilenleri unutur).\n",
    "- Context window dolarsa, **eski bilgiler atılır** (genellikle baştan).\n",
    "\n",
    "\n",
    "### Context Window ile Başa Çıkma Stratejileri\n",
    "\n",
    "| Strateji | Açıklama |\n",
    "| --- | --- |\n",
    "| **Map-Reduce** | Belge parçalara bölünür, her parça özetlenir, özetler birleştirilir. |\n",
    "| **Refine** | İlk parça özetlenir, ikinci parça eklenir, önceki özetle birlikte yeniden özetlenir. |\n",
    "| **RAG + Chunking** | Bilgi veritabanı küçük parçalara (chunk) bölünür. Sadece ilgili chunk’lar kullanılır. |\n",
    "| **Sliding Window** | Yeni token’lar geldikçe eski baştaki token’lar atılır. |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32875ad",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
