{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5e4173a",
   "metadata": {},
   "source": [
    "### 6. Embedding Mantığı\n",
    "\n",
    "### Nedir Bu Embedding?\n",
    "\n",
    "**Embedding**, kelimeleri veya cümleleri, anlamsal olarak yakın olanlar birbirine yakın olacak şekilde sayısal vektörlere dönüştürme işlemidir.\n",
    "\n",
    "Örneğin:\n",
    "\n",
    "- \"kral\" → `[0.8, 1.2, -0.3, 0.9]`\n",
    "- \"kraliçe\" → `[0.75, 1.1, -0.2, 0.88]`\n",
    "- \"erkek\" → `[0.82, 0.5, 0.1, 0.3]`\n",
    "- \"kadın\" → `[0.78, 0.48, 0.08, 0.32]`\n",
    "\n",
    "Burada:\n",
    "\n",
    "`kral - erkek + kadın ≈ kraliçe`\n",
    "\n",
    "Bu, embedding’lerin **anlamsal ilişkileri** yakalayabildiğini gösterir.\n",
    "\n",
    "---\n",
    "\n",
    "### Neden Gerekli?\n",
    "\n",
    "- Bilgisayarlar metni doğrudan anlayamaz.\n",
    "- Kelimeleri sayısal hale getirerek, matematiksel işlemler yapılabilir.\n",
    "- Yakınlık, benzerlik, karşıtlık gibi ilişkiler vektör uzayında modellenebilir.\n",
    "\n",
    "---\n",
    "\n",
    "### Word2Vec, GloVe vs BERT Embedding\n",
    "\n",
    "| Yöntem | Özellik |\n",
    "| --- | --- |\n",
    "| **Word2Vec** | Her kelime için sabit bir vektör (bağlamdan bağımsız). \"Banka\" her zaman aynı. |\n",
    "| **GloVe** | Küresel kelime eş oluşum istatistiklerine dayalı. |\n",
    "| **BERT Embedding** | **Bağlama duyarlı (contextual)**. \"Banka\" kelimesi \"banka hesabı\" ve \"nehir bankı\" cümlelerinde farklı vektörlere sahip olur. |\n",
    "\n",
    "Bu yüzden günümüzde BERT tabanlı embedding’ler tercih edilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56fe1bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46470b43",
   "metadata": {},
   "source": [
    "Embedding, kelimeleri sayısal vektörlere dönüştürme işlemidir.\n",
    "\n",
    "- 1970'ler: One-hot encoding → Sparse, anlamsız\n",
    "- 2013: Word2Vec → \"Kral - Adam + Kadın = Kraliçe\"\n",
    "- 2018: BERT → Bağlama göre değişir (\"bank\" = nehir / banka)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04842bac",
   "metadata": {},
   "source": [
    "# Türkçe BERT Model Alternatifleri\n",
    "\n",
    "\"dbmdz/bert-base-turkish-uncased-mc5\" modeli yerine önerilebilecek en uygun alternatifler:\n",
    "\n",
    "## 1. Önerilen Temel Model: loodos/bert-base-turkish-uncased\n",
    "\n",
    "Bu model, 12 encoder katmanlı ve 768 gizli katman boyutuna sahip Türkçe için eğitilmiş BERT-Base modelidir.  \n",
    "\n",
    "**Avantajları:**\n",
    "- Büyük Türkçe web veri seti üzerinde eğitilmiş\n",
    "- \"Uncased\" yapısı ile küçük/büyük harf duyarlılığı olmadan çalışır\n",
    "- Hugging Face kütüphanesi ile tam uyumlu\n",
    "\n",
    "**Kullanım Örneği:**\n",
    "```python\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "model_name = \"loodos/bert-base-turkish-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "inputs = tokenizer(\"Merhaba dünya\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "```\n",
    "\n",
    "## 2. Trendyol/tybert\n",
    "\n",
    "Trendyol tarafından geliştirilmiş bu model, çeşitli doğal dil anlama görevleri için optimize edilmiştir. \n",
    "\n",
    "**Avantajları:**\n",
    "- Ticari uygulamalarda test edilmiş\n",
    "- Türkçe'nin güncel kullanımına uygun\n",
    "- İyi performans gösteriyor\n",
    "\n",
    "**Kullanım:**\n",
    "```python\n",
    "model_name = \"Trendyol/tybert\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "```\n",
    "\n",
    "## 3. Özel Görevlere Yönelik Modeller\n",
    "\n",
    "### İsimlendirilmiş Varlık Tanıma (NER) için:\n",
    "- **akdeniz27/bert-base-turkish-cased-ner**: dbmdz/bert-base-turkish-cased modelinin İsimlendirilmiş Varlık Tanıma için fine-tune edilmiş hali. \n",
    "- **girayyagmur/bert-base-turkish-ner-cased**: Türkçe NER görevinde yüksek doğruluk oranlarına ulaşmış bir model. \n",
    "\n",
    "### Tıp Alanı Soru-Cevaplama için:\n",
    "- **kaixkhazaki/turkish-medical-question-answering**: dbmdz/bert-base-turkish-cased modelinin tıp alanında soru-cevaplama için optimize edilmiş hali. \n",
    "\n",
    "## Hangi Modeli Seçmeli?\n",
    "\n",
    "- **Genel metin işleme için**: `loodos/bert-base-turkish-uncased` (en iyi genel performans)\n",
    "- **E-ticaret veya ticari uygulamalar için**: `Trendyol/tybert` \n",
    "- **Özel görevler (NER, soru-cevaplama) için**: Göreve özel fine-tune edilmiş modeller\n",
    "\n",
    "**Not**: Eğer metinlerinizde büyük/küçük harf duyarlılığı önemliyse, cased modelleri değerlendirebilirsiniz. Ancak Türkçe için genellikle uncased modeller tercih edilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a0409",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
