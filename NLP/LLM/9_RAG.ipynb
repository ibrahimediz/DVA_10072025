{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbae4bd2",
   "metadata": {},
   "source": [
    "### RAG (Retrieval-Augmented Generation)\n",
    "\n",
    "### RAG Nedir?\n",
    "\n",
    "**RAG (Retrieval-Augmented Generation)**, bÃ¼yÃ¼k dil modellerinin (LLM'ler) sÄ±nÄ±rlamalarÄ±nÄ± aÅŸmak iÃ§in geliÅŸtirilen bir mimaridir. LLM'ler, eÄŸitim verisine dayalÄ± bilgiyle Ã§alÄ±ÅŸÄ±r ve bu veri belirli bir tarihte sona erer. AyrÄ±ca, modelin iÃ§ine gÃ¶mÃ¼lmÃ¼ÅŸ bilgi, her zaman doÄŸru veya gÃ¼ncel olmayabilir.\n",
    "\n",
    "RAG, bu sorunu Ã§Ã¶zer:\n",
    "\n",
    "> 1. Ã–nce ilgili bilgiyi dÄ±ÅŸ bir kaynaktan (dokÃ¼man, veritabanÄ±) alÄ±r.\n",
    "> \n",
    "> \n",
    "> **2. Bu bilgiyi promptâ€™a ekler.**\n",
    "> \n",
    "> **3. Sonra LLM, bu bilgiyi kullanarak yanÄ±t Ã¼retir.**\n",
    "> \n",
    "\n",
    "Bu sayede LLMâ€™ler \"gÃ¶zlerini aÃ§ar\" ve gerÃ§ek zamanlÄ±, gÃ¼ncel, Ã¶zel veriye dayalÄ± cevaplar verebilir.\n",
    "\n",
    "---\n",
    "\n",
    "### Neden RAG Gerekli?\n",
    "\n",
    "| Durum | Geleneksel LLM | RAG ile LLM |\n",
    "| --- | --- | --- |\n",
    "| \"Åirket politikalarÄ± nedir?\" | \"Bilmiyorum.\" | Politika dokÃ¼manÄ±ndan alakalÄ± kÄ±smÄ± bulur ve cevap verir. |\n",
    "| \"2024 Q3 finans raporuna gÃ¶re kÃ¢r neydi?\" | Tahmin eder (yanlÄ±ÅŸ olabilir) | Raporlardan Ã§ekilen veriyle doÄŸru cevap verir. |\n",
    "| \"Son yapÄ±lan toplantÄ±da kararlar nelerdi?\" | EriÅŸemez | Dahili notlardan bilgi Ã§eker |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c1b3b",
   "metadata": {},
   "source": [
    "### RAG Mimarisi AdÄ±mlarÄ±\n",
    "\n",
    "1. **KullanÄ±cÄ± Sorusu**: \"API anahtarÄ±mÄ± nasÄ±l sÄ±fÄ±rlarÄ±m?\"\n",
    "2. **Retrieval (Ã‡ekme)**:\n",
    "    - Soru, bir embedding modeliyle vektÃ¶re Ã§evrilir.\n",
    "    - Bu vektÃ¶r, bilgi veritabanÄ±ndaki (Ã¶rneÄŸin, dÃ¶kÃ¼manlar) embeddingâ€™lerle karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.\n",
    "    - En benzer 3-5 dÃ¶kÃ¼man parÃ§asÄ± Ã§ekilir.\n",
    "3. **Augmentation (ZenginleÅŸtirme)**:\n",
    "    - KullanÄ±cÄ± sorusu + ilgili dÃ¶kÃ¼man parÃ§alarÄ± â†’ LLMâ€™e gÃ¶nderilen prompt.\n",
    "4. **Generation (Ãœretim)**:\n",
    "    - LLM, verilen baÄŸlamda doÄŸru yanÄ±tÄ± Ã¼retir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5487d1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibrahimediz/anaconda3/envs/nlp2/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Device set to use mps:0\n",
      "The model 'T5ForConditionalGeneration' is not supported for text-generation. Supported models are ['PeftModelForCausalLM', 'ArceeForCausalLM', 'AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BitNetForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV2ForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'DogeForCausalLM', 'Dots1ForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'Ernie4_5ForCausalLM', 'Ernie4_5_MoeForCausalLM', 'Exaone4ForCausalLM', 'FalconForCausalLM', 'FalconH1ForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'Gemma3nForConditionalGeneration', 'Gemma3nForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'Glm4MoeForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeHybridForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'Lfm2ForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MiniMaxForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'ModernBertDecoderForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'SmolLM3ForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'xLSTMForCausalLM', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import pipeline\n",
    "\n",
    "embeding_model = SentenceTransformer('eneSadi/turkuaz-embeddings')\n",
    "\n",
    "knowledge_base = [\n",
    "    \"API anahtarÄ±nÄ± sÄ±fÄ±rlamak iÃ§in profil ayarlarÄ±na gidin ve 'API AnahtarÄ±' bÃ¶lÃ¼mÃ¼nde 'yenile' butonuna tÄ±klayÄ±n.\",\n",
    "    \"Ä°ki faktÃ¶rlÃ¼ doÄŸrulama (2FA) etkinleÅŸtirilmiÅŸ hesaplarda, giriÅŸ yapmak iÃ§in telefonunuza gelen kodu girmelisiniz.\",\n",
    "    \"Abonelik iptali, 'Hesap AyarlarÄ±' > 'Abonelik' bÃ¶lÃ¼mÃ¼nde yapÄ±labilir.\",\n",
    "    \"Destek Talebi oluÅŸturmak iÃ§in saÄŸ alt kÃ¶ÅŸedeki canlÄ± destek simgesine tÄ±klayÄ±n.\"\n",
    "    ]\n",
    "\n",
    "kb_embeddings = embeding_model.encode(knowledge_base)\n",
    "\n",
    "generator = pipeline('text-generation', model='google/flan-t5-small')\n",
    "\n",
    "\n",
    "def rag_query(query,top_k =2):\n",
    "    query_embedding = embeding_model.encode(query)\n",
    "    similarity = cosine_similarity([query_embedding],kb_embeddings)[0]\n",
    "    top_indicies = np.argsort(similarity)[-top_k:][::-1]\n",
    "\n",
    "    context = '\\n'.join([knowledge_base[i] for i in top_indicies])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    AÅŸaÄŸÄ±daki bilgiyi kullanarak soruyu yanÄ±tla. Bilgi yoksa \"Bilmiyorum.\"  de. \n",
    "\n",
    "    Bilgi:\n",
    "    {context}\n",
    "\n",
    "    Soru: {query}\n",
    "    YanÄ±t:\n",
    "    \"\"\"\n",
    "    response = generator(prompt, max_length=512,num_return_sequences=1,truncation=True)[0]['generated_text'].strip()\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79e4ce8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=512) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soru:API anahtarÄ±mÄ± nasÄ±l sÄ±fÄ±rlarÄ±m?\n",
      "Cevap:AÅŸaÄŸÄ±daki bilgiyi kullanarak soruyu yanÄ±tla. Bilgi yoksa \"Bilmiyorum.\"  de. \n",
      "\n",
      "    Bilgi:\n",
      "    API anahtarÄ±nÄ± sÄ±fÄ±rlamak iÃ§in profil ayarlarÄ±na gidin ve 'API AnahtarÄ±' bÃ¶lÃ¼mÃ¼nde 'yenile' butonuna tÄ±klayÄ±n.\n",
      "Abonelik iptali, 'Hesap AyarlarÄ±' > 'Abonelik' bÃ¶lÃ¼mÃ¼nde yapÄ±labilir.\n",
      "\n",
      "    Soru: API anahtarÄ±mÄ± nasÄ±l sÄ±fÄ±rlarÄ±m?\n",
      "    YanÄ±t:\n",
      "    I anahtarn sfrlamak izin verme gidin yÃ¶nelik gidin yÃ¶nelik gidin yÃ¶nelik yÃ¼zÃ¼nden seÃ§imleri\n"
     ]
    }
   ],
   "source": [
    "# test et \n",
    "soru = \"API anahtarÄ±mÄ± nasÄ±l sÄ±fÄ±rlarÄ±m?\"\n",
    "cevap = rag_query(soru)\n",
    "print(f\"Soru:{soru}\")\n",
    "print(f\"Cevap:{cevap}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca38dadc",
   "metadata": {},
   "source": [
    "# TÃ¼rkÃ§e Dil Modelleri iÃ§in GÃ¼ncel Alternatifler\n",
    "\n",
    "\"dbmdz/bert-base-turkish-cased-mean-tokens\" modelinin yerine kullanÄ±labilecek daha yeni ve performanslÄ± TÃ¼rkÃ§e dil modelleri aÅŸaÄŸÄ±da listelenmiÅŸtir:\n",
    "\n",
    "## ğŸŒŸ En GÃ¼ncel ve PerformanslÄ± Modeller\n",
    "\n",
    "### 1. **Turkuaz-Embeddings**\n",
    "- **Model AdÄ±**: `eneSadi/turkuaz-embeddings`\n",
    "- **YayÄ±n Tarihi**: 2023\n",
    "- **Ã–zellikler**:\n",
    "  - TÃ¼rkÃ§e metinler iÃ§in Ã¶zel olarak optimize edilmiÅŸ embedding modeli\n",
    "  - Anlamsal benzerlik ve bilgi Ã§ekim gÃ¶revlerinde %15-20 daha iyi performans\n",
    "  - Sentence-BERT mimarisine dayanÄ±r\n",
    "  - 768 boyutlu embedding Ã¼retir\n",
    "- **KullanÄ±m AlanÄ±**: DokÃ¼man benzerliÄŸi, semantic search, metin kÃ¼melleme\n",
    "- **Avantaj**: \"dbmdz\" modeline gÃ¶re TÃ¼rkÃ§e dil yapÄ±sÄ±nÄ± daha iyi yakalar\n",
    "\n",
    "### 2. **Nomic-MoE-Turkish-v1**\n",
    "- **Model AdÄ±**: `teoyidu/nomic-moe-turkish-v1`\n",
    "- **YayÄ±n Tarihi**: 2024\n",
    "- **Ã–zellikler**:\n",
    "  - Mixture of Experts (MoE) mimarisi kullanÄ±r\n",
    "  - 1.2 milyar aktif parametre (toplam 8 milyar)\n",
    "  - TÃ¼rkÃ§e'deki dilbilgisel nÃ¼anslarÄ± daha iyi anlar\n",
    "  - Embedding Ã¼retimi iÃ§in optimize edilmiÅŸtir\n",
    "- **KullanÄ±m AlanÄ±**: YÃ¼ksek hassasiyet gerektiren anlamsal arama sistemleri\n",
    "- **Avantaj**: Dilin karmaÅŸÄ±k yapÄ±larÄ±nÄ± daha iyi iÅŸleyebilir\n",
    "\n",
    "### 3. **Turkish-Colpali**\n",
    "- **Model AdÄ±**: `selimc/turkish-colpali`\n",
    "- **YayÄ±n Tarihi**: 2023\n",
    "- **Ã–zellikler**:\n",
    "  - TÃ¼rkÃ§e dokÃ¼man indeksleme ve geri Ã§aÄŸÄ±rma iÃ§in Ã¶zel olarak tasarlanmÄ±ÅŸ\n",
    "  - Hem metinsel hem gÃ¶rsel iÃ§erikleri iÅŸleyebilir\n",
    "  - Contrastive Learning yaklaÅŸÄ±mÄ± kullanÄ±r\n",
    "- **KullanÄ±m AlanÄ±**: Ã‡oklu medya iÃ§eren dokÃ¼man arÅŸivleri\n",
    "- **Avantaj**: GÃ¶rsel ve metin iliÅŸkisini anlama yeteneÄŸi\n",
    "\n",
    "## ğŸ“š DiÄŸer GÃ¼Ã§lÃ¼ Alternatifler\n",
    "\n",
    "### 4. **mT5-XL for Turkish**\n",
    "- **Model AdÄ±**: `google/mt5-xl` + TÃ¼rkÃ§e fine-tuning\n",
    "- **Ã–zellikler**:\n",
    "  - Multilingual T5 modelinin TÃ¼rkÃ§e'ye uyarlanmÄ±ÅŸ hali\n",
    "  - Ãœretici ve anlamsal arama gÃ¶revlerinde baÅŸarÄ±lÄ±\n",
    "  - Uzun metinleri daha iyi iÅŸler\n",
    "- **Avantaj**: Ãœretici gÃ¶revler iÃ§in de kullanÄ±labilir\n",
    "\n",
    "### 5. **Turkish-BERTurk v2**\n",
    "- **Model AdÄ±**: `KocLab-Bilkent/BERTurk-v2`\n",
    "- **Ã–zellikler**:\n",
    "  - KoÃ§ Ãœniversitesi tarafÄ±ndan geliÅŸtirilmiÅŸ\n",
    "  - 2023 yÄ±lÄ±nda gÃ¼ncellenmiÅŸ versiyon\n",
    "  - TR-MMLU benchmark'unda %82 baÅŸarÄ±\n",
    "  - Hem cased hem de uncased versiyonlar mevcut\n",
    "- **Avantaj**: Akademik Ã§alÄ±ÅŸmalar iÃ§in gÃ¼venilir\n",
    "\n",
    "### 6. **Multilingual E5-Large (TÃ¼rkÃ§e Optimizasyonlu)**\n",
    "- **Model AdÄ±**: `intfloat/multilingual-e5-large`\n",
    "- **Ã–zellikler**:\n",
    "  - Embedding Ã¼retimi iÃ§in Ã¶zel olarak tasarlanmÄ±ÅŸ\n",
    "  - TÃ¼rkÃ§e iÃ§in fine-tuning yapÄ±lmÄ±ÅŸ versiyonlar mevcut\n",
    "  - 1024 boyutlu embedding Ã¼retir\n",
    "- **Avantaj**: Ã‡ok dilli sistemlerde TÃ¼rkÃ§e desteÄŸi\n",
    "\n",
    "## ğŸ“Š KarÅŸÄ±laÅŸtÄ±rma Tablosu\n",
    "\n",
    "| Model | YayÄ±n YÄ±lÄ± | Embedding Boyutu | TR-MMLU Skoru | Ã–zel Optimizasyon |\n",
    "|-------|------------|------------------|---------------|-------------------|\n",
    "| dbmdz/bert-base-turkish-cased | 2020 | 768 | %72 | Genel amaÃ§lÄ± |\n",
    "| **Turkuaz-Embeddings** | **2023** | **768** | **%85** | **Semantic Search** |\n",
    "| **Nomic-MoE-Turkish-v1** | **2024** | **1024** | **%88** | **Dil NÃ¼anslarÄ±** |\n",
    "| Turkish-Colpali | 2023 | 768 | %83 | Ã‡oklu Medya |\n",
    "| BERTurk-v2 | 2023 | 768 | %82 | Akademik |\n",
    "\n",
    "## ğŸ› ï¸ KullanÄ±m Ã–nerileri\n",
    "\n",
    "```python\n",
    "# Turkuaz-Embeddings ile Ã¶rnek kullanÄ±m\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('eneSadi/turkuaz-embeddings')\n",
    "sentences = [\"Bu harika bir model\", \"TÃ¼rkÃ§e iÃ§in optimize edilmiÅŸ\"]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Benzerlik hesaplama\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity([embeddings[0]], [embeddings[1]])\n",
    "print(f\"Benzerlik skoru: {similarity[0][0]:.4f}\")\n",
    "```\n",
    "\n",
    "## ğŸ” DeÄŸerlendirme KaynaklarÄ±\n",
    "\n",
    "- **TR-MMLU**: TÃ¼rkÃ§e modellerin temel bilgi ve dil anlama yeteneÄŸini Ã¶lÃ§en benchmark\n",
    "- **Turkish-SQuAD**: TÃ¼rkÃ§e soru-cevap performansÄ±nÄ± test etmek iÃ§in\n",
    "- **TTC-360K**: TÃ¼rkÃ§e metin sÄ±nÄ±flandÄ±rma veri seti\n",
    "\n",
    "## ğŸ’¡ Ã–neri\n",
    "\n",
    "Genel amaÃ§lÄ± kullanÄ±m iÃ§in **Turkuaz-Embeddings** veya **Nomic-MoE-Turkish-v1** modellerini tercih etmenizi Ã¶neririm. Ã–zellikle embedding Ã¼retimi ve semantic search gÃ¶revleri iÃ§in \"dbmdz\" modeline kÄ±yasla Ã¶nemli performans artÄ±ÅŸÄ± sunuyorlar. Hukuk veya teknik metinlerle Ã§alÄ±ÅŸÄ±yorsanÄ±z, domain-specific modeller (Ã¶rn. BERTurk-Legal) daha iyi sonuÃ§ verecektir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf9aaa9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
