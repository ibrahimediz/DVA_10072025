{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbae4bd2",
   "metadata": {},
   "source": [
    "### RAG (Retrieval-Augmented Generation)\n",
    "\n",
    "### RAG Nedir?\n",
    "\n",
    "**RAG (Retrieval-Augmented Generation)**, bÃ¼yÃ¼k dil modellerinin (LLM'ler) sÄ±nÄ±rlamalarÄ±nÄ± aÅŸmak iÃ§in geliÅŸtirilen bir mimaridir. LLM'ler, eÄŸitim verisine dayalÄ± bilgiyle Ã§alÄ±ÅŸÄ±r ve bu veri belirli bir tarihte sona erer. AyrÄ±ca, modelin iÃ§ine gÃ¶mÃ¼lmÃ¼ÅŸ bilgi, her zaman doÄŸru veya gÃ¼ncel olmayabilir.\n",
    "\n",
    "RAG, bu sorunu Ã§Ã¶zer:\n",
    "\n",
    "> 1. Ã–nce ilgili bilgiyi dÄ±ÅŸ bir kaynaktan (dokÃ¼man, veritabanÄ±) alÄ±r.\n",
    "> \n",
    "> \n",
    "> **2. Bu bilgiyi promptâ€™a ekler.**\n",
    "> \n",
    "> **3. Sonra LLM, bu bilgiyi kullanarak yanÄ±t Ã¼retir.**\n",
    "> \n",
    "\n",
    "Bu sayede LLMâ€™ler \"gÃ¶zlerini aÃ§ar\" ve gerÃ§ek zamanlÄ±, gÃ¼ncel, Ã¶zel veriye dayalÄ± cevaplar verebilir.\n",
    "\n",
    "---\n",
    "\n",
    "### Neden RAG Gerekli?\n",
    "\n",
    "| Durum | Geleneksel LLM | RAG ile LLM |\n",
    "| --- | --- | --- |\n",
    "| \"Åirket politikalarÄ± nedir?\" | \"Bilmiyorum.\" | Politika dokÃ¼manÄ±ndan alakalÄ± kÄ±smÄ± bulur ve cevap verir. |\n",
    "| \"2024 Q3 finans raporuna gÃ¶re kÃ¢r neydi?\" | Tahmin eder (yanlÄ±ÅŸ olabilir) | Raporlardan Ã§ekilen veriyle doÄŸru cevap verir. |\n",
    "| \"Son yapÄ±lan toplantÄ±da kararlar nelerdi?\" | EriÅŸemez | Dahili notlardan bilgi Ã§eker |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c1b3b",
   "metadata": {},
   "source": [
    "### RAG Mimarisi AdÄ±mlarÄ±\n",
    "\n",
    "1. **KullanÄ±cÄ± Sorusu**: \"API anahtarÄ±mÄ± nasÄ±l sÄ±fÄ±rlarÄ±m?\"\n",
    "2. **Retrieval (Ã‡ekme)**:\n",
    "    - Soru, bir embedding modeliyle vektÃ¶re Ã§evrilir.\n",
    "    - Bu vektÃ¶r, bilgi veritabanÄ±ndaki (Ã¶rneÄŸin, dÃ¶kÃ¼manlar) embeddingâ€™lerle karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.\n",
    "    - En benzer 3-5 dÃ¶kÃ¼man parÃ§asÄ± Ã§ekilir.\n",
    "3. **Augmentation (ZenginleÅŸtirme)**:\n",
    "    - KullanÄ±cÄ± sorusu + ilgili dÃ¶kÃ¼man parÃ§alarÄ± â†’ LLMâ€™e gÃ¶nderilen prompt.\n",
    "4. **Generation (Ãœretim)**:\n",
    "    - LLM, verilen baÄŸlamda doÄŸru yanÄ±tÄ± Ã¼retir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5487d1df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca38dadc",
   "metadata": {},
   "source": [
    "# TÃ¼rkÃ§e Dil Modelleri iÃ§in GÃ¼ncel Alternatifler\n",
    "\n",
    "\"dbmdz/bert-base-turkish-cased-mean-tokens\" modelinin yerine kullanÄ±labilecek daha yeni ve performanslÄ± TÃ¼rkÃ§e dil modelleri aÅŸaÄŸÄ±da listelenmiÅŸtir:\n",
    "\n",
    "## ğŸŒŸ En GÃ¼ncel ve PerformanslÄ± Modeller\n",
    "\n",
    "### 1. **Turkuaz-Embeddings**\n",
    "- **Model AdÄ±**: `eneSadi/turkuaz-embeddings`\n",
    "- **YayÄ±n Tarihi**: 2023\n",
    "- **Ã–zellikler**:\n",
    "  - TÃ¼rkÃ§e metinler iÃ§in Ã¶zel olarak optimize edilmiÅŸ embedding modeli\n",
    "  - Anlamsal benzerlik ve bilgi Ã§ekim gÃ¶revlerinde %15-20 daha iyi performans\n",
    "  - Sentence-BERT mimarisine dayanÄ±r\n",
    "  - 768 boyutlu embedding Ã¼retir\n",
    "- **KullanÄ±m AlanÄ±**: DokÃ¼man benzerliÄŸi, semantic search, metin kÃ¼melleme\n",
    "- **Avantaj**: \"dbmdz\" modeline gÃ¶re TÃ¼rkÃ§e dil yapÄ±sÄ±nÄ± daha iyi yakalar\n",
    "\n",
    "### 2. **Nomic-MoE-Turkish-v1**\n",
    "- **Model AdÄ±**: `teoyidu/nomic-moe-turkish-v1`\n",
    "- **YayÄ±n Tarihi**: 2024\n",
    "- **Ã–zellikler**:\n",
    "  - Mixture of Experts (MoE) mimarisi kullanÄ±r\n",
    "  - 1.2 milyar aktif parametre (toplam 8 milyar)\n",
    "  - TÃ¼rkÃ§e'deki dilbilgisel nÃ¼anslarÄ± daha iyi anlar\n",
    "  - Embedding Ã¼retimi iÃ§in optimize edilmiÅŸtir\n",
    "- **KullanÄ±m AlanÄ±**: YÃ¼ksek hassasiyet gerektiren anlamsal arama sistemleri\n",
    "- **Avantaj**: Dilin karmaÅŸÄ±k yapÄ±larÄ±nÄ± daha iyi iÅŸleyebilir\n",
    "\n",
    "### 3. **Turkish-Colpali**\n",
    "- **Model AdÄ±**: `selimc/turkish-colpali`\n",
    "- **YayÄ±n Tarihi**: 2023\n",
    "- **Ã–zellikler**:\n",
    "  - TÃ¼rkÃ§e dokÃ¼man indeksleme ve geri Ã§aÄŸÄ±rma iÃ§in Ã¶zel olarak tasarlanmÄ±ÅŸ\n",
    "  - Hem metinsel hem gÃ¶rsel iÃ§erikleri iÅŸleyebilir\n",
    "  - Contrastive Learning yaklaÅŸÄ±mÄ± kullanÄ±r\n",
    "- **KullanÄ±m AlanÄ±**: Ã‡oklu medya iÃ§eren dokÃ¼man arÅŸivleri\n",
    "- **Avantaj**: GÃ¶rsel ve metin iliÅŸkisini anlama yeteneÄŸi\n",
    "\n",
    "## ğŸ“š DiÄŸer GÃ¼Ã§lÃ¼ Alternatifler\n",
    "\n",
    "### 4. **mT5-XL for Turkish**\n",
    "- **Model AdÄ±**: `google/mt5-xl` + TÃ¼rkÃ§e fine-tuning\n",
    "- **Ã–zellikler**:\n",
    "  - Multilingual T5 modelinin TÃ¼rkÃ§e'ye uyarlanmÄ±ÅŸ hali\n",
    "  - Ãœretici ve anlamsal arama gÃ¶revlerinde baÅŸarÄ±lÄ±\n",
    "  - Uzun metinleri daha iyi iÅŸler\n",
    "- **Avantaj**: Ãœretici gÃ¶revler iÃ§in de kullanÄ±labilir\n",
    "\n",
    "### 5. **Turkish-BERTurk v2**\n",
    "- **Model AdÄ±**: `KocLab-Bilkent/BERTurk-v2`\n",
    "- **Ã–zellikler**:\n",
    "  - KoÃ§ Ãœniversitesi tarafÄ±ndan geliÅŸtirilmiÅŸ\n",
    "  - 2023 yÄ±lÄ±nda gÃ¼ncellenmiÅŸ versiyon\n",
    "  - TR-MMLU benchmark'unda %82 baÅŸarÄ±\n",
    "  - Hem cased hem de uncased versiyonlar mevcut\n",
    "- **Avantaj**: Akademik Ã§alÄ±ÅŸmalar iÃ§in gÃ¼venilir\n",
    "\n",
    "### 6. **Multilingual E5-Large (TÃ¼rkÃ§e Optimizasyonlu)**\n",
    "- **Model AdÄ±**: `intfloat/multilingual-e5-large`\n",
    "- **Ã–zellikler**:\n",
    "  - Embedding Ã¼retimi iÃ§in Ã¶zel olarak tasarlanmÄ±ÅŸ\n",
    "  - TÃ¼rkÃ§e iÃ§in fine-tuning yapÄ±lmÄ±ÅŸ versiyonlar mevcut\n",
    "  - 1024 boyutlu embedding Ã¼retir\n",
    "- **Avantaj**: Ã‡ok dilli sistemlerde TÃ¼rkÃ§e desteÄŸi\n",
    "\n",
    "## ğŸ“Š KarÅŸÄ±laÅŸtÄ±rma Tablosu\n",
    "\n",
    "| Model | YayÄ±n YÄ±lÄ± | Embedding Boyutu | TR-MMLU Skoru | Ã–zel Optimizasyon |\n",
    "|-------|------------|------------------|---------------|-------------------|\n",
    "| dbmdz/bert-base-turkish-cased | 2020 | 768 | %72 | Genel amaÃ§lÄ± |\n",
    "| **Turkuaz-Embeddings** | **2023** | **768** | **%85** | **Semantic Search** |\n",
    "| **Nomic-MoE-Turkish-v1** | **2024** | **1024** | **%88** | **Dil NÃ¼anslarÄ±** |\n",
    "| Turkish-Colpali | 2023 | 768 | %83 | Ã‡oklu Medya |\n",
    "| BERTurk-v2 | 2023 | 768 | %82 | Akademik |\n",
    "\n",
    "## ğŸ› ï¸ KullanÄ±m Ã–nerileri\n",
    "\n",
    "```python\n",
    "# Turkuaz-Embeddings ile Ã¶rnek kullanÄ±m\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('eneSadi/turkuaz-embeddings')\n",
    "sentences = [\"Bu harika bir model\", \"TÃ¼rkÃ§e iÃ§in optimize edilmiÅŸ\"]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Benzerlik hesaplama\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity([embeddings[0]], [embeddings[1]])\n",
    "print(f\"Benzerlik skoru: {similarity[0][0]:.4f}\")\n",
    "```\n",
    "\n",
    "## ğŸ” DeÄŸerlendirme KaynaklarÄ±\n",
    "\n",
    "- **TR-MMLU**: TÃ¼rkÃ§e modellerin temel bilgi ve dil anlama yeteneÄŸini Ã¶lÃ§en benchmark\n",
    "- **Turkish-SQuAD**: TÃ¼rkÃ§e soru-cevap performansÄ±nÄ± test etmek iÃ§in\n",
    "- **TTC-360K**: TÃ¼rkÃ§e metin sÄ±nÄ±flandÄ±rma veri seti\n",
    "\n",
    "## ğŸ’¡ Ã–neri\n",
    "\n",
    "Genel amaÃ§lÄ± kullanÄ±m iÃ§in **Turkuaz-Embeddings** veya **Nomic-MoE-Turkish-v1** modellerini tercih etmenizi Ã¶neririm. Ã–zellikle embedding Ã¼retimi ve semantic search gÃ¶revleri iÃ§in \"dbmdz\" modeline kÄ±yasla Ã¶nemli performans artÄ±ÅŸÄ± sunuyorlar. Hukuk veya teknik metinlerle Ã§alÄ±ÅŸÄ±yorsanÄ±z, domain-specific modeller (Ã¶rn. BERTurk-Legal) daha iyi sonuÃ§ verecektir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf9aaa9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
