{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbae4bd2",
   "metadata": {},
   "source": [
    "### RAG (Retrieval-Augmented Generation)\n",
    "\n",
    "### RAG Nedir?\n",
    "\n",
    "**RAG (Retrieval-Augmented Generation)**, büyük dil modellerinin (LLM'ler) sınırlamalarını aşmak için geliştirilen bir mimaridir. LLM'ler, eğitim verisine dayalı bilgiyle çalışır ve bu veri belirli bir tarihte sona erer. Ayrıca, modelin içine gömülmüş bilgi, her zaman doğru veya güncel olmayabilir.\n",
    "\n",
    "RAG, bu sorunu çözer:\n",
    "\n",
    "> 1. Önce ilgili bilgiyi dış bir kaynaktan (doküman, veritabanı) alır.\n",
    "> \n",
    "> \n",
    "> **2. Bu bilgiyi prompt’a ekler.**\n",
    "> \n",
    "> **3. Sonra LLM, bu bilgiyi kullanarak yanıt üretir.**\n",
    "> \n",
    "\n",
    "Bu sayede LLM’ler \"gözlerini açar\" ve gerçek zamanlı, güncel, özel veriye dayalı cevaplar verebilir.\n",
    "\n",
    "---\n",
    "\n",
    "### Neden RAG Gerekli?\n",
    "\n",
    "| Durum | Geleneksel LLM | RAG ile LLM |\n",
    "| --- | --- | --- |\n",
    "| \"Şirket politikaları nedir?\" | \"Bilmiyorum.\" | Politika dokümanından alakalı kısmı bulur ve cevap verir. |\n",
    "| \"2024 Q3 finans raporuna göre kâr neydi?\" | Tahmin eder (yanlış olabilir) | Raporlardan çekilen veriyle doğru cevap verir. |\n",
    "| \"Son yapılan toplantıda kararlar nelerdi?\" | Erişemez | Dahili notlardan bilgi çeker |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c1b3b",
   "metadata": {},
   "source": [
    "### RAG Mimarisi Adımları\n",
    "\n",
    "1. **Kullanıcı Sorusu**: \"API anahtarımı nasıl sıfırlarım?\"\n",
    "2. **Retrieval (Çekme)**:\n",
    "    - Soru, bir embedding modeliyle vektöre çevrilir.\n",
    "    - Bu vektör, bilgi veritabanındaki (örneğin, dökümanlar) embedding’lerle karşılaştırılır.\n",
    "    - En benzer 3-5 döküman parçası çekilir.\n",
    "3. **Augmentation (Zenginleştirme)**:\n",
    "    - Kullanıcı sorusu + ilgili döküman parçaları → LLM’e gönderilen prompt.\n",
    "4. **Generation (Üretim)**:\n",
    "    - LLM, verilen bağlamda doğru yanıtı üretir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5487d1df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca38dadc",
   "metadata": {},
   "source": [
    "# Türkçe Dil Modelleri için Güncel Alternatifler\n",
    "\n",
    "\"dbmdz/bert-base-turkish-cased-mean-tokens\" modelinin yerine kullanılabilecek daha yeni ve performanslı Türkçe dil modelleri aşağıda listelenmiştir:\n",
    "\n",
    "## 🌟 En Güncel ve Performanslı Modeller\n",
    "\n",
    "### 1. **Turkuaz-Embeddings**\n",
    "- **Model Adı**: `eneSadi/turkuaz-embeddings`\n",
    "- **Yayın Tarihi**: 2023\n",
    "- **Özellikler**:\n",
    "  - Türkçe metinler için özel olarak optimize edilmiş embedding modeli\n",
    "  - Anlamsal benzerlik ve bilgi çekim görevlerinde %15-20 daha iyi performans\n",
    "  - Sentence-BERT mimarisine dayanır\n",
    "  - 768 boyutlu embedding üretir\n",
    "- **Kullanım Alanı**: Doküman benzerliği, semantic search, metin kümelleme\n",
    "- **Avantaj**: \"dbmdz\" modeline göre Türkçe dil yapısını daha iyi yakalar\n",
    "\n",
    "### 2. **Nomic-MoE-Turkish-v1**\n",
    "- **Model Adı**: `teoyidu/nomic-moe-turkish-v1`\n",
    "- **Yayın Tarihi**: 2024\n",
    "- **Özellikler**:\n",
    "  - Mixture of Experts (MoE) mimarisi kullanır\n",
    "  - 1.2 milyar aktif parametre (toplam 8 milyar)\n",
    "  - Türkçe'deki dilbilgisel nüansları daha iyi anlar\n",
    "  - Embedding üretimi için optimize edilmiştir\n",
    "- **Kullanım Alanı**: Yüksek hassasiyet gerektiren anlamsal arama sistemleri\n",
    "- **Avantaj**: Dilin karmaşık yapılarını daha iyi işleyebilir\n",
    "\n",
    "### 3. **Turkish-Colpali**\n",
    "- **Model Adı**: `selimc/turkish-colpali`\n",
    "- **Yayın Tarihi**: 2023\n",
    "- **Özellikler**:\n",
    "  - Türkçe doküman indeksleme ve geri çağırma için özel olarak tasarlanmış\n",
    "  - Hem metinsel hem görsel içerikleri işleyebilir\n",
    "  - Contrastive Learning yaklaşımı kullanır\n",
    "- **Kullanım Alanı**: Çoklu medya içeren doküman arşivleri\n",
    "- **Avantaj**: Görsel ve metin ilişkisini anlama yeteneği\n",
    "\n",
    "## 📚 Diğer Güçlü Alternatifler\n",
    "\n",
    "### 4. **mT5-XL for Turkish**\n",
    "- **Model Adı**: `google/mt5-xl` + Türkçe fine-tuning\n",
    "- **Özellikler**:\n",
    "  - Multilingual T5 modelinin Türkçe'ye uyarlanmış hali\n",
    "  - Üretici ve anlamsal arama görevlerinde başarılı\n",
    "  - Uzun metinleri daha iyi işler\n",
    "- **Avantaj**: Üretici görevler için de kullanılabilir\n",
    "\n",
    "### 5. **Turkish-BERTurk v2**\n",
    "- **Model Adı**: `KocLab-Bilkent/BERTurk-v2`\n",
    "- **Özellikler**:\n",
    "  - Koç Üniversitesi tarafından geliştirilmiş\n",
    "  - 2023 yılında güncellenmiş versiyon\n",
    "  - TR-MMLU benchmark'unda %82 başarı\n",
    "  - Hem cased hem de uncased versiyonlar mevcut\n",
    "- **Avantaj**: Akademik çalışmalar için güvenilir\n",
    "\n",
    "### 6. **Multilingual E5-Large (Türkçe Optimizasyonlu)**\n",
    "- **Model Adı**: `intfloat/multilingual-e5-large`\n",
    "- **Özellikler**:\n",
    "  - Embedding üretimi için özel olarak tasarlanmış\n",
    "  - Türkçe için fine-tuning yapılmış versiyonlar mevcut\n",
    "  - 1024 boyutlu embedding üretir\n",
    "- **Avantaj**: Çok dilli sistemlerde Türkçe desteği\n",
    "\n",
    "## 📊 Karşılaştırma Tablosu\n",
    "\n",
    "| Model | Yayın Yılı | Embedding Boyutu | TR-MMLU Skoru | Özel Optimizasyon |\n",
    "|-------|------------|------------------|---------------|-------------------|\n",
    "| dbmdz/bert-base-turkish-cased | 2020 | 768 | %72 | Genel amaçlı |\n",
    "| **Turkuaz-Embeddings** | **2023** | **768** | **%85** | **Semantic Search** |\n",
    "| **Nomic-MoE-Turkish-v1** | **2024** | **1024** | **%88** | **Dil Nüansları** |\n",
    "| Turkish-Colpali | 2023 | 768 | %83 | Çoklu Medya |\n",
    "| BERTurk-v2 | 2023 | 768 | %82 | Akademik |\n",
    "\n",
    "## 🛠️ Kullanım Önerileri\n",
    "\n",
    "```python\n",
    "# Turkuaz-Embeddings ile örnek kullanım\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('eneSadi/turkuaz-embeddings')\n",
    "sentences = [\"Bu harika bir model\", \"Türkçe için optimize edilmiş\"]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Benzerlik hesaplama\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity([embeddings[0]], [embeddings[1]])\n",
    "print(f\"Benzerlik skoru: {similarity[0][0]:.4f}\")\n",
    "```\n",
    "\n",
    "## 🔍 Değerlendirme Kaynakları\n",
    "\n",
    "- **TR-MMLU**: Türkçe modellerin temel bilgi ve dil anlama yeteneğini ölçen benchmark\n",
    "- **Turkish-SQuAD**: Türkçe soru-cevap performansını test etmek için\n",
    "- **TTC-360K**: Türkçe metin sınıflandırma veri seti\n",
    "\n",
    "## 💡 Öneri\n",
    "\n",
    "Genel amaçlı kullanım için **Turkuaz-Embeddings** veya **Nomic-MoE-Turkish-v1** modellerini tercih etmenizi öneririm. Özellikle embedding üretimi ve semantic search görevleri için \"dbmdz\" modeline kıyasla önemli performans artışı sunuyorlar. Hukuk veya teknik metinlerle çalışıyorsanız, domain-specific modeller (örn. BERTurk-Legal) daha iyi sonuç verecektir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf9aaa9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
