{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbae4bd2",
   "metadata": {},
   "source": [
    "### RAG (Retrieval-Augmented Generation)\n",
    "\n",
    "### RAG Nedir?\n",
    "\n",
    "**RAG (Retrieval-Augmented Generation)**, büyük dil modellerinin (LLM'ler) sınırlamalarını aşmak için geliştirilen bir mimaridir. LLM'ler, eğitim verisine dayalı bilgiyle çalışır ve bu veri belirli bir tarihte sona erer. Ayrıca, modelin içine gömülmüş bilgi, her zaman doğru veya güncel olmayabilir.\n",
    "\n",
    "RAG, bu sorunu çözer:\n",
    "\n",
    "> 1. Önce ilgili bilgiyi dış bir kaynaktan (doküman, veritabanı) alır.\n",
    "> \n",
    "> \n",
    "> **2. Bu bilgiyi prompt’a ekler.**\n",
    "> \n",
    "> **3. Sonra LLM, bu bilgiyi kullanarak yanıt üretir.**\n",
    "> \n",
    "\n",
    "Bu sayede LLM’ler \"gözlerini açar\" ve gerçek zamanlı, güncel, özel veriye dayalı cevaplar verebilir.\n",
    "\n",
    "---\n",
    "\n",
    "### Neden RAG Gerekli?\n",
    "\n",
    "| Durum | Geleneksel LLM | RAG ile LLM |\n",
    "| --- | --- | --- |\n",
    "| \"Şirket politikaları nedir?\" | \"Bilmiyorum.\" | Politika dokümanından alakalı kısmı bulur ve cevap verir. |\n",
    "| \"2024 Q3 finans raporuna göre kâr neydi?\" | Tahmin eder (yanlış olabilir) | Raporlardan çekilen veriyle doğru cevap verir. |\n",
    "| \"Son yapılan toplantıda kararlar nelerdi?\" | Erişemez | Dahili notlardan bilgi çeker |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c1b3b",
   "metadata": {},
   "source": [
    "### RAG Mimarisi Adımları\n",
    "\n",
    "1. **Kullanıcı Sorusu**: \"API anahtarımı nasıl sıfırlarım?\"\n",
    "2. **Retrieval (Çekme)**:\n",
    "    - Soru, bir embedding modeliyle vektöre çevrilir.\n",
    "    - Bu vektör, bilgi veritabanındaki (örneğin, dökümanlar) embedding’lerle karşılaştırılır.\n",
    "    - En benzer 3-5 döküman parçası çekilir.\n",
    "3. **Augmentation (Zenginleştirme)**:\n",
    "    - Kullanıcı sorusu + ilgili döküman parçaları → LLM’e gönderilen prompt.\n",
    "4. **Generation (Üretim)**:\n",
    "    - LLM, verilen bağlamda doğru yanıtı üretir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5487d1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibrahimediz/anaconda3/envs/nlp2/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Device set to use mps:0\n",
      "The model 'T5ForConditionalGeneration' is not supported for text-generation. Supported models are ['PeftModelForCausalLM', 'ArceeForCausalLM', 'AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BitNetForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV2ForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'DogeForCausalLM', 'Dots1ForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'Ernie4_5ForCausalLM', 'Ernie4_5_MoeForCausalLM', 'Exaone4ForCausalLM', 'FalconForCausalLM', 'FalconH1ForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'Gemma3nForConditionalGeneration', 'Gemma3nForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'Glm4MoeForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeHybridForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'Lfm2ForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MiniMaxForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'ModernBertDecoderForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'SmolLM3ForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'xLSTMForCausalLM', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import pipeline\n",
    "\n",
    "embeding_model = SentenceTransformer('eneSadi/turkuaz-embeddings')\n",
    "\n",
    "knowledge_base = [\n",
    "    \"API anahtarını sıfırlamak için profil ayarlarına gidin ve 'API Anahtarı' bölümünde 'yenile' butonuna tıklayın.\",\n",
    "    \"İki faktörlü doğrulama (2FA) etkinleştirilmiş hesaplarda, giriş yapmak için telefonunuza gelen kodu girmelisiniz.\",\n",
    "    \"Abonelik iptali, 'Hesap Ayarları' > 'Abonelik' bölümünde yapılabilir.\",\n",
    "    \"Destek Talebi oluşturmak için sağ alt köşedeki canlı destek simgesine tıklayın.\"\n",
    "    ]\n",
    "\n",
    "kb_embeddings = embeding_model.encode(knowledge_base)\n",
    "\n",
    "generator = pipeline('text-generation', model='google/flan-t5-small')\n",
    "\n",
    "\n",
    "def rag_query(query,top_k =2):\n",
    "    query_embedding = embeding_model.encode(query)\n",
    "    similarity = cosine_similarity([query_embedding],kb_embeddings)[0]\n",
    "    top_indicies = np.argsort(similarity)[-top_k:][::-1]\n",
    "\n",
    "    context = '\\n'.join([knowledge_base[i] for i in top_indicies])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Aşağıdaki bilgiyi kullanarak soruyu yanıtla. Bilgi yoksa \"Bilmiyorum.\"  de. \n",
    "\n",
    "    Bilgi:\n",
    "    {context}\n",
    "\n",
    "    Soru: {query}\n",
    "    Yanıt:\n",
    "    \"\"\"\n",
    "    response = generator(prompt, max_length=512,num_return_sequences=1,truncation=True)[0]['generated_text'].strip()\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79e4ce8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=512) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soru:API anahtarımı nasıl sıfırlarım?\n",
      "Cevap:Aşağıdaki bilgiyi kullanarak soruyu yanıtla. Bilgi yoksa \"Bilmiyorum.\"  de. \n",
      "\n",
      "    Bilgi:\n",
      "    API anahtarını sıfırlamak için profil ayarlarına gidin ve 'API Anahtarı' bölümünde 'yenile' butonuna tıklayın.\n",
      "Abonelik iptali, 'Hesap Ayarları' > 'Abonelik' bölümünde yapılabilir.\n",
      "\n",
      "    Soru: API anahtarımı nasıl sıfırlarım?\n",
      "    Yanıt:\n",
      "    I anahtarn sfrlamak izin verme gidin yönelik gidin yönelik gidin yönelik yüzünden seçimleri\n"
     ]
    }
   ],
   "source": [
    "# test et \n",
    "soru = \"API anahtarımı nasıl sıfırlarım?\"\n",
    "cevap = rag_query(soru)\n",
    "print(f\"Soru:{soru}\")\n",
    "print(f\"Cevap:{cevap}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca38dadc",
   "metadata": {},
   "source": [
    "# Türkçe Dil Modelleri için Güncel Alternatifler\n",
    "\n",
    "\"dbmdz/bert-base-turkish-cased-mean-tokens\" modelinin yerine kullanılabilecek daha yeni ve performanslı Türkçe dil modelleri aşağıda listelenmiştir:\n",
    "\n",
    "## 🌟 En Güncel ve Performanslı Modeller\n",
    "\n",
    "### 1. **Turkuaz-Embeddings**\n",
    "- **Model Adı**: `eneSadi/turkuaz-embeddings`\n",
    "- **Yayın Tarihi**: 2023\n",
    "- **Özellikler**:\n",
    "  - Türkçe metinler için özel olarak optimize edilmiş embedding modeli\n",
    "  - Anlamsal benzerlik ve bilgi çekim görevlerinde %15-20 daha iyi performans\n",
    "  - Sentence-BERT mimarisine dayanır\n",
    "  - 768 boyutlu embedding üretir\n",
    "- **Kullanım Alanı**: Doküman benzerliği, semantic search, metin kümelleme\n",
    "- **Avantaj**: \"dbmdz\" modeline göre Türkçe dil yapısını daha iyi yakalar\n",
    "\n",
    "### 2. **Nomic-MoE-Turkish-v1**\n",
    "- **Model Adı**: `teoyidu/nomic-moe-turkish-v1`\n",
    "- **Yayın Tarihi**: 2024\n",
    "- **Özellikler**:\n",
    "  - Mixture of Experts (MoE) mimarisi kullanır\n",
    "  - 1.2 milyar aktif parametre (toplam 8 milyar)\n",
    "  - Türkçe'deki dilbilgisel nüansları daha iyi anlar\n",
    "  - Embedding üretimi için optimize edilmiştir\n",
    "- **Kullanım Alanı**: Yüksek hassasiyet gerektiren anlamsal arama sistemleri\n",
    "- **Avantaj**: Dilin karmaşık yapılarını daha iyi işleyebilir\n",
    "\n",
    "### 3. **Turkish-Colpali**\n",
    "- **Model Adı**: `selimc/turkish-colpali`\n",
    "- **Yayın Tarihi**: 2023\n",
    "- **Özellikler**:\n",
    "  - Türkçe doküman indeksleme ve geri çağırma için özel olarak tasarlanmış\n",
    "  - Hem metinsel hem görsel içerikleri işleyebilir\n",
    "  - Contrastive Learning yaklaşımı kullanır\n",
    "- **Kullanım Alanı**: Çoklu medya içeren doküman arşivleri\n",
    "- **Avantaj**: Görsel ve metin ilişkisini anlama yeteneği\n",
    "\n",
    "## 📚 Diğer Güçlü Alternatifler\n",
    "\n",
    "### 4. **mT5-XL for Turkish**\n",
    "- **Model Adı**: `google/mt5-xl` + Türkçe fine-tuning\n",
    "- **Özellikler**:\n",
    "  - Multilingual T5 modelinin Türkçe'ye uyarlanmış hali\n",
    "  - Üretici ve anlamsal arama görevlerinde başarılı\n",
    "  - Uzun metinleri daha iyi işler\n",
    "- **Avantaj**: Üretici görevler için de kullanılabilir\n",
    "\n",
    "### 5. **Turkish-BERTurk v2**\n",
    "- **Model Adı**: `KocLab-Bilkent/BERTurk-v2`\n",
    "- **Özellikler**:\n",
    "  - Koç Üniversitesi tarafından geliştirilmiş\n",
    "  - 2023 yılında güncellenmiş versiyon\n",
    "  - TR-MMLU benchmark'unda %82 başarı\n",
    "  - Hem cased hem de uncased versiyonlar mevcut\n",
    "- **Avantaj**: Akademik çalışmalar için güvenilir\n",
    "\n",
    "### 6. **Multilingual E5-Large (Türkçe Optimizasyonlu)**\n",
    "- **Model Adı**: `intfloat/multilingual-e5-large`\n",
    "- **Özellikler**:\n",
    "  - Embedding üretimi için özel olarak tasarlanmış\n",
    "  - Türkçe için fine-tuning yapılmış versiyonlar mevcut\n",
    "  - 1024 boyutlu embedding üretir\n",
    "- **Avantaj**: Çok dilli sistemlerde Türkçe desteği\n",
    "\n",
    "## 📊 Karşılaştırma Tablosu\n",
    "\n",
    "| Model | Yayın Yılı | Embedding Boyutu | TR-MMLU Skoru | Özel Optimizasyon |\n",
    "|-------|------------|------------------|---------------|-------------------|\n",
    "| dbmdz/bert-base-turkish-cased | 2020 | 768 | %72 | Genel amaçlı |\n",
    "| **Turkuaz-Embeddings** | **2023** | **768** | **%85** | **Semantic Search** |\n",
    "| **Nomic-MoE-Turkish-v1** | **2024** | **1024** | **%88** | **Dil Nüansları** |\n",
    "| Turkish-Colpali | 2023 | 768 | %83 | Çoklu Medya |\n",
    "| BERTurk-v2 | 2023 | 768 | %82 | Akademik |\n",
    "\n",
    "## 🛠️ Kullanım Önerileri\n",
    "\n",
    "```python\n",
    "# Turkuaz-Embeddings ile örnek kullanım\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('eneSadi/turkuaz-embeddings')\n",
    "sentences = [\"Bu harika bir model\", \"Türkçe için optimize edilmiş\"]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Benzerlik hesaplama\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity([embeddings[0]], [embeddings[1]])\n",
    "print(f\"Benzerlik skoru: {similarity[0][0]:.4f}\")\n",
    "```\n",
    "\n",
    "## 🔍 Değerlendirme Kaynakları\n",
    "\n",
    "- **TR-MMLU**: Türkçe modellerin temel bilgi ve dil anlama yeteneğini ölçen benchmark\n",
    "- **Turkish-SQuAD**: Türkçe soru-cevap performansını test etmek için\n",
    "- **TTC-360K**: Türkçe metin sınıflandırma veri seti\n",
    "\n",
    "## 💡 Öneri\n",
    "\n",
    "Genel amaçlı kullanım için **Turkuaz-Embeddings** veya **Nomic-MoE-Turkish-v1** modellerini tercih etmenizi öneririm. Özellikle embedding üretimi ve semantic search görevleri için \"dbmdz\" modeline kıyasla önemli performans artışı sunuyorlar. Hukuk veya teknik metinlerle çalışıyorsanız, domain-specific modeller (örn. BERTurk-Legal) daha iyi sonuç verecektir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf9aaa9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
