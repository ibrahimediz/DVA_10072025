{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fc26d72",
   "metadata": {},
   "source": [
    "### 2. HuggingFace Kütüphanesi\n",
    "\n",
    "### Neden HuggingFace?\n",
    "\n",
    "HuggingFace, doğal dil işleme (NLP) alanında devrim yaratmış bir açık kaynak platformudur. Özellikle `transformers` kütüphanesi sayesinde, BERT, GPT, T5 gibi karmaşık modelleri sadece birkaç satır kodla indirip kullanabiliyoruz.\n",
    "\n",
    "HuggingFace’in sunduğu temel bileşenler:\n",
    "\n",
    "- **`transformers`**: Önceden eğitilmiş modeller ve tokenizer’lar.\n",
    "- **`datasets`**: 30.000+ NLP veri kümesi.\n",
    "- **`tokenizers`**: Hızlı ve esnek tokenleştirme.\n",
    "- **`hub`**: Herkesin modellerini paylaştığı platform (model zoo).\n",
    "- **`accelerate`**: Dağıtık eğitim desteği.\n",
    "---\n",
    "### Ana Kavramlar\n",
    "\n",
    "- **Model**: Dil modeli (örneğin `bert-base-uncased`).\n",
    "- **Tokenizer**: Metni modele girdi olarak verilebilecek sayısal forma dönüştürür.\n",
    "- **Pipeline**: Ortak NLP görevleri (sınıflandırma, çeviri, soru-cevap) için hazır fonksiyonlar.\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "### Temel Özellikler:\n",
    "\n",
    "- 300.000+ önceden eğitilmiş model (BERT, RoBERTa, DeBERTa, etc.)\n",
    "- 2.000+ dil desteği (Türkçe de dahil)\n",
    "- Kolay fine-tuning ve dağıtım\n",
    "- Pipeline API: Satır kodla model kullan\n",
    "---\n",
    "\n",
    "\n",
    "### Kod Uygulaması: HuggingFace ile Metin Sınıflandırma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc22903",
   "metadata": {},
   "source": [
    "```\n",
    "%pip install transformers torch datasets\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b34c7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "/Users/ibrahimediz/anaconda3/envs/nlp2/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hızlı kargo,kaliteli ürün => {'label': 'positive', 'score': 0.9931176900863647}\n",
      "Kalitesiz ürün iade ettim => {'label': 'negative', 'score': 0.9992490410804749}\n",
      "iyi ama fiyatına göre beklediğim gibi değil => {'label': 'negative', 'score': 0.9981688261032104}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\",model=\"savasy/bert-base-turkish-sentiment-cased\")\n",
    "\n",
    "yorumlar = [\n",
    "    \"Hızlı kargo,kaliteli ürün\",\n",
    "    \"Kalitesiz ürün iade ettim\",\n",
    "    \"iyi ama fiyatına göre beklediğim gibi değil\"\n",
    "]\n",
    "\n",
    "sonuclar = classifier(yorumlar)\n",
    "\n",
    "for yorum,sonuc in zip(yorumlar,sonuclar):\n",
    "    print(f\"{yorum} => {sonuc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a1af7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibrahimediz/anaconda3/envs/nlp2/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metin: Çok iyi çok güzel çok ta iyi oldu tamam mı?\n",
      "Tahmin:OLUMLU,Güven:0.9949\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_name = \"savasy/bert-base-turkish-sentiment-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "text = \"Çok iyi çok güzel çok ta iyi oldu tamam mı?\"\n",
    "\n",
    "inputs = tokenizer(\n",
    "    text,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "probs = torch.softmax(outputs.logits,dim=-1)\n",
    "pred_label = torch.argmax(probs,dim=-1).item()\n",
    "\n",
    "labels = [\"OLUMSUZ\",\"OLUMLU\"]\n",
    "print(\"Metin:\",text)\n",
    "print(f\"Tahmin:{labels[pred_label]},Güven:{probs[0][pred_label]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a39d697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
