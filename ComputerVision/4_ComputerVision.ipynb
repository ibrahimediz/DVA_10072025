{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a82002",
   "metadata": {},
   "source": [
    "# Transfer Öğrenme: Hazır Modelleri Kullanmak\n",
    "a. Transfer Öğrenme Nedir?\n",
    "Transfer Öğrenme (Transfer Learning), önceden büyük veri setlerinde (örneğin ImageNet) eğitilmiş bir modeli, yeni bir görev için yeniden kullanma tekniğidir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf6a289",
   "metadata": {},
   "source": [
    "### Popüler Hazır Modeller\n",
    "\n",
    "- **VGG16 / VGG19**: Basit, anlaşılır yapı. İyi özellik çıkarır.\n",
    "- **ResNet50**: Derin ağlar için atık bağlantılar (skip connections) kullanır.\n",
    "- **MobileNet**: Mobil cihazlar için optimize edilmiştir, hafiftir.\n",
    "- **EfficientNet**: Yüksek doğruluk, düşük hesaplama maliyeti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "017a7045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models,optimizers\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97668284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibrahimediz/anaconda3/envs/ortamCV/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 2s/step - accuracy: 0.7890 - loss: 0.8558 - val_accuracy: 0.9647 - val_loss: 0.1016\n",
      "Epoch 2/5\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 2s/step - accuracy: 0.9020 - loss: 0.3148 - val_accuracy: 0.9728 - val_loss: 0.0796\n",
      "Epoch 3/5\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 2s/step - accuracy: 0.9395 - loss: 0.2233 - val_accuracy: 0.9788 - val_loss: 0.0673\n",
      "Epoch 4/5\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 2s/step - accuracy: 0.9405 - loss: 0.1908 - val_accuracy: 0.9708 - val_loss: 0.0903\n",
      "Epoch 5/5\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 2s/step - accuracy: 0.9505 - loss: 0.1501 - val_accuracy: 0.9718 - val_loss: 0.0783\n"
     ]
    }
   ],
   "source": [
    "base_dir = './cats_and_dogs_filtered'\n",
    "train_dir = os.path.join(base_dir,'train')\n",
    "validation_dir = os.path.join(base_dir,'validation')\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                     batch_size=16,\n",
    "                     class_mode='binary',\n",
    "                     target_size=(224,224))\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir,\n",
    "                     batch_size=16,\n",
    "                     class_mode='binary',\n",
    "                     target_size=(224,224))\n",
    "\n",
    "base_model = VGG16(weights='imagenet',\n",
    "include_top=False,input_shape=(224,224,3))\n",
    "\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(512,activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
    "                    epochs=5,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=validation_generator.samples//validation_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92722c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 1s/step - accuracy: 0.9720 - loss: 0.0777\n",
      "Test accuracy:  0.972000002861023\n",
      "Test loss:  0.07771778851747513\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy: ',test_acc)\n",
    "print('Test loss: ',test_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b28c89",
   "metadata": {},
   "source": [
    "## Fine Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbd424f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 2s/step - accuracy: 0.9600 - loss: 0.1144 - val_accuracy: 0.9748 - val_loss: 0.0661\n",
      "Epoch 2/5\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 2s/step - accuracy: 0.9645 - loss: 0.1015 - val_accuracy: 0.9859 - val_loss: 0.0373\n",
      "Epoch 3/5\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 2s/step - accuracy: 0.9805 - loss: 0.0595 - val_accuracy: 0.9819 - val_loss: 0.0403\n",
      "Epoch 4/5\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 2s/step - accuracy: 0.9765 - loss: 0.0653 - val_accuracy: 0.9768 - val_loss: 0.0655\n",
      "Epoch 5/5\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 2s/step - accuracy: 0.9835 - loss: 0.0517 - val_accuracy: 0.9849 - val_loss: 0.0410\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(1e-5),\n",
    "loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
    "                    epochs=5,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=validation_generator.samples//validation_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed58a48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ortamCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
