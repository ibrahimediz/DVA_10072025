{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6774c9fb",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "* Problem Cümlemiz : LSTM ile ürün yorumları üzerinden metin türetme görevi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dcc3fc",
   "metadata": {},
   "source": [
    "## Kütüphanelerin Yüklenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13a570a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kullanılan Cihaz:  cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Kullanılan Cihaz: \",device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1163cce4",
   "metadata": {},
   "source": [
    "## Veri Yükleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1959c69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metin</th>\n",
       "      <th>Durum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evet anlatıldığı gibi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daha öncede almıştım bu cihazdan ense ve sakal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ürün gayet başarılı sakal kesmede başlık sayıs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Daha öncede aynısını almıştım çok güzel ve kal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Erkek kuaförüyüm ense ve sıfır sakal traşı içi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Metin  Durum\n",
       "0                              evet anlatıldığı gibi      1\n",
       "1  Daha öncede almıştım bu cihazdan ense ve sakal...      1\n",
       "2  Ürün gayet başarılı sakal kesmede başlık sayıs...      1\n",
       "3  Daha öncede aynısını almıştım çok güzel ve kal...      1\n",
       "4  Erkek kuaförüyüm ense ve sıfır sakal traşı içi...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"e-ticaret_urun_yorumlari.csv\",delimiter=\";\",encoding=\"utf-8\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed6d792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15170 entries, 0 to 15169\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Metin   15170 non-null  object\n",
      " 1   Durum   15170 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 237.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f66d195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam Veri Sayısı: 15170\n"
     ]
    }
   ],
   "source": [
    "texts = df[\"Metin\"].tolist()\n",
    "print(\"Toplam Veri Sayısı:\",len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa15415a",
   "metadata": {},
   "source": [
    "## veri temizleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d61972b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Örnek Temizlenmiş Metin: tavsiye edebileceğim çok güzel bir makina\n",
      "Temizlenmemiş Metin: tavsiye edebileceğim çok güzel bir makina\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9ıüöğçş]\",' ',text) # türkçe karakterlerde dikkate alındı\n",
    "    text = re.sub(r'\\\\s+',' ',text).strip()\n",
    "    return text\n",
    "# ÖDEV :  veri temizleme dökümanını inceleyerek yazım düzeltmeler için gerekli kodlar eklenebilir\n",
    "temiz_metinler = [clean_text(text) for text in texts]\n",
    "print(\"Örnek Temizlenmiş Metin:\",temiz_metinler[8])\n",
    "print(\"Temizlenmemiş Metin:\",texts[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f650e293",
   "metadata": {},
   "source": [
    "## Tokenizasyon ve Sözlük Oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "041e3da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam Kelime Sayısı: 5002\n",
      "Örnek Eşleme: 'ürün' -> 3\n"
     ]
    }
   ],
   "source": [
    "# kelime frekans analizi ve sözlük oluşturma \n",
    "kelimeler = \" \".join(temiz_metinler).split()\n",
    "frekans = Counter(kelimeler)\n",
    "en_cok_kelimeler = frekans.most_common(5000)\n",
    "\n",
    "# sozluk : Kelime -> İndis\n",
    "kelime2idx = {\"<PAD>\":0,\"<OOV>\":1} # 0 : padding ve 1 : out of vocabulary\n",
    "for idx,(kelime,_) in enumerate(en_cok_kelimeler,2): # 2 den başlayarak en sık kullanılan 5000 kelimeyle sözlük oluşturuyoruz\n",
    "    kelime2idx[kelime] = idx\n",
    "\n",
    "# idx2kelime : İndis -> Kelime Ters Sözlük\n",
    "idx2kelime = {idx:kelime for kelime,idx in kelime2idx.items()}\n",
    "\n",
    "toplam_kelime = len(kelime2idx)\n",
    "print(f\"Toplam Kelime Sayısı: {toplam_kelime}\")\n",
    "print(f\"Örnek Eşleme: 'ürün' -> {kelime2idx.get('ürün',1)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247ad0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[227, 2, 137]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 227, 2, 137]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kelimeler = [\"evet\",\"çok\",\"başarılı\"]\n",
    "# seq = [kelime2idx.get(kelime,1) for kelime in kelimeler]\n",
    "# print(seq)\n",
    "# if len(seq) < 25:\n",
    "#     seq = [0] * (25-len(seq)) + seq\n",
    "# else:\n",
    "#     seq = seq[:25] # eğer çok uzunsa kes\n",
    "# seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca2f032",
   "metadata": {},
   "source": [
    "## Sequence Oluşturma ve Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad4d8c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (15170, 25)\n",
      "Örnek Sequence [   0    0    0    0    0    0    0    3  246    6  160   18   45    1\n",
      "    4  143   62    1  255   15 2178    7  145  156   54]\n"
     ]
    }
   ],
   "source": [
    "max_len = 25 # sabit sequence uzuluğu\n",
    "sequences = []\n",
    "\n",
    "for metin in temiz_metinler:\n",
    "    kelimeler = metin.split()\n",
    "    seq = [kelime2idx.get(kelime,1) for kelime in kelimeler] # Bilinmeyenler için OOV kullanıldı\n",
    "\n",
    "    if len(seq) < max_len:\n",
    "        seq = [0] * (max_len-len(seq)) + seq\n",
    "    else:\n",
    "        seq = seq[:max_len] # eğer çok uzunsa kes\n",
    "    sequences.append(seq)\n",
    "\n",
    "X = np.array(sequences)\n",
    "print(\"X.shape:\",X.shape)\n",
    "print(\"Örnek Sequence\",X[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617b8d23",
   "metadata": {},
   "source": [
    "## LSTM Modelini Tanımlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c01c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMGenerator(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_dim,hidden_dim,num_layers):\n",
    "        super(LSTMGenerator,self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim,hidden_dim,num_layers,batch_first=True,dropout=0.2)\n",
    "        self.fc = nn.Linear(hidden_dim,vocab_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ =self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77fd628",
   "metadata": {},
   "source": [
    "## Hiper Parametreler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530109d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_embedding_dim = 128 # Denge: 64 (hafif) - 128 (orta) - 256 (kuvvetli)\n",
    "hp_hidden_dim = 256 # LSTM Bellek Kapasitesi \n",
    "hp_num_layers = 2 # Derinlik : 1 (hafif) - 2 (orta) - 3 (kuvvetli)  daha karmaşık kalıpları öğrenebilmesi için sayı arttırılmalı"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0371ef",
   "metadata": {},
   "source": [
    "## Modeli Oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9f59a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Oluşturuldu\n"
     ]
    }
   ],
   "source": [
    "model = LSTMGenerator(\n",
    "                    vocab_size=toplam_kelime,\n",
    "                    embedding_dim=hp_embedding_dim,\n",
    "                    hidden_dim=hp_hidden_dim,\n",
    "                    num_layers=hp_hidden_dim).to(device)\n",
    "\n",
    "print(\"Model Oluşturuldu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e36f94",
   "metadata": {},
   "source": [
    "## Modelin Eğitimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54c23256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100,Loss:0.1019\n",
      "Epoch 11/100,Loss:0.0751\n",
      "Epoch 21/100,Loss:0.0626\n",
      "Epoch 31/100,Loss:0.0521\n",
      "Epoch 41/100,Loss:0.0441\n",
      "Epoch 51/100,Loss:0.0387\n",
      "Epoch 61/100,Loss:0.0342\n",
      "Epoch 71/100,Loss:0.0313\n",
      "Epoch 81/100,Loss:0.0292\n",
      "Epoch 91/100,Loss:0.0270\n"
     ]
    }
   ],
   "source": [
    "# Eğitim Parametreleri\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0) # paddingi ignore et\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001) # \n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs): \n",
    "    total_loss = 0\n",
    "    for i in range(0,len(X),batch_size):\n",
    "        # batch hazırla\n",
    "        X_batch = X[i:i+batch_size] # girdi\n",
    "        y_bacth = np.copy(X_batch) # hedef bir sonraki kelime\n",
    "        y_batch = np.roll(y_bacth,-1,axis=1) # hedefi kaydır\n",
    "        y_bacth[:,-1] = 0 # son kelimeyi padding yap\n",
    "\n",
    "        # Tensor'a Çevir\n",
    "        X_tensor = torch.tensor(X_batch,dtype=torch.long).to(device)\n",
    "        y_tensor = torch.tensor(y_batch,dtype=torch.long).to(device)\n",
    "\n",
    "        # ileri besleme\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_tensor) # (batch seq vocab)\n",
    "\n",
    "\n",
    "        loss = criterion(outputs.view(-1,toplam_kelime),y_tensor.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs},Loss:{total_loss/len(X):.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3fdba6",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f040c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yorum_uret(baslangic,max_uzunluk=20):\n",
    "    model.eval()\n",
    "    cumle = clean_text(baslangic)\n",
    "    kelimeler = cumle.split()\n",
    "\n",
    "    # ilk sequence oluştur\n",
    "    seq = [kelime2idx.get(kelime,1) for kelime in kelimeler]\n",
    "    seq = [0]*(max_len - len(seq)) + seq\n",
    "\n",
    "    for _ in range(max_uzunluk):\n",
    "        \n",
    "        input_tensor = torch.tensor([seq[-max_len:]],dtype=torch.long).to(device)\n",
    "        # tahmin\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            tahmin = output[0,-1,:].argmax().item()\n",
    "\n",
    "        # kelimeye çevir\n",
    "        tahminlenen_kelime = idx2kelime.get(tahmin,\"<OOV>\")\n",
    "\n",
    "        # Dögüyü kır\n",
    "        if tahminlenen_kelime in [\".\",\"!\",'?',\"<OOV>\"] or len(kelimeler) > 50:\n",
    "            break\n",
    "\n",
    "        kelimeler.append(tahminlenen_kelime)\n",
    "        seq.append(tahmin)\n",
    "\n",
    "    return \" \".join(kelimeler)\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10fd933",
   "metadata": {},
   "source": [
    "## Örnek üretim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ecba698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Üretilen Yorumlar:\n",
      "1. 'ürün' ile başla: ürün çok küçüktü ve kalitesizdi tavsiye etmiyorum iade ettim\n",
      "2. 'kalitesi iyi,çok beğendim' ile başla kalitesi iyi çok beğendim tavsiye ederim ayrıca\n",
      "3. 'hızlı kargo' ile başla hızlı kargo ve güvenilir alışveriş için atlamak için uygun değil beğenmedim almayın iade edeceğim beğenmedim çok kalitesiz bir\n"
     ]
    }
   ],
   "source": [
    "print(\"Üretilen Yorumlar:\")\n",
    "print(\"1. 'ürün' ile başla:\",yorum_uret(\"ürün\"))\n",
    "print(\"2. 'kalitesi iyi,çok beğendim' ile başla\",yorum_uret(\"kalitesi iyi,çok beğendim\"))\n",
    "print(\"3. 'hızlı kargo' ile başla\",yorum_uret(\"hızlı kargo\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b82b36",
   "metadata": {},
   "source": [
    "## Modeli Kaydetme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32f2ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'kelime2idx': kelime2idx,\n",
    "    'idx2kelime': idx2kelime,\n",
    "    'max_len': max_len\n",
    "},\n",
    "           'urun_yorumu_uret.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025ea2a7",
   "metadata": {},
   "source": [
    "## Modeli Yükleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28ae3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_embedding_dim = 128 # Denge: 64 (hafif) - 128 (orta) - 256 (kuvvetli)\n",
    "hp_hidden_dim = 256 # LSTM Bellek Kapasitesi \n",
    "hp_num_layers = 2 # Derinlik : 1 (hafif) - 2 (orta) - 3 (kuvvetli)  daha karmaşık kalıpları öğrenebilmesi için sayı arttırılmalı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5988f40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMGenerator(\n",
       "  (embedding): Embedding(5002, 128)\n",
       "  (lstm): LSTM(128, 256, num_layers=256, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=256, out_features=5002, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMGenerator(vocab_size=toplam_kelime,embedding_dim=hp_embedding_dim,hidden_dim=hp_hidden_dim,num_layers=hp_hidden_dim).to(device)\n",
    "checkpoint = torch.load('/Users/ibrahimediz/Documents/Github/DVA_10072025/DeepLearning/urun_yorumu_uret.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "kelime2idx = checkpoint['kelime2idx']\n",
    "idx2kelime = checkpoint['idx2kelime']\n",
    "max_len = checkpoint['max_len']\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ba8f1e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0087b8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
